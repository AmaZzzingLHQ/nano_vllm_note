=== Qwen3模型结构信息 ===

模型路径: /opt/llm/Qwen3-0.6B/
模型类型: Qwen3ForCausalLM
设备: cuda:0
总参数量: 596,049,920 (1136.88 MB)

=== 模型配置 ===
vocab_size: 151936
max_position_embeddings: 40960
hidden_size: 1024
intermediate_size: 3072
num_hidden_layers: 28
num_attention_heads: 16
use_sliding_window: False
sliding_window: None
max_window_layers: 28
num_key_value_heads: 8
head_dim: 128
hidden_act: silu
initializer_range: 0.02
rms_norm_eps: 1e-06
use_cache: True
rope_theta: 1000000
rope_scaling: None
attention_bias: False
attention_dropout: 0.0
layer_types: ['full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention']
return_dict: True
output_hidden_states: False
torchscript: False
dtype: torch.float16
pruned_heads: {}
tie_word_embeddings: True
chunk_size_feed_forward: 0
is_encoder_decoder: False
is_decoder: False
cross_attention_hidden_size: None
add_cross_attention: False
tie_encoder_decoder: False
architectures: ['Qwen3ForCausalLM']
finetuning_task: None
id2label: {0: 'LABEL_0', 1: 'LABEL_1'}
label2id: {'LABEL_0': 0, 'LABEL_1': 1}
task_specific_params: None
problem_type: None
tokenizer_class: None
prefix: None
bos_token_id: 151643
pad_token_id: None
eos_token_id: 151645
sep_token_id: None
decoder_start_token_id: None
max_length: 20
min_length: 0
do_sample: False
early_stopping: False
num_beams: 1
num_beam_groups: 1
diversity_penalty: 0.0
temperature: 1.0
top_k: 50
top_p: 1.0
typical_p: 1.0
repetition_penalty: 1.0
length_penalty: 1.0
no_repeat_ngram_size: 0
encoder_no_repeat_ngram_size: 0
bad_words_ids: None
num_return_sequences: 1
output_scores: False
return_dict_in_generate: False
forced_bos_token_id: None
forced_eos_token_id: None
remove_invalid_values: False
exponential_decay_length_penalty: None
suppress_tokens: None
begin_suppress_tokens: None
transformers_version: 4.51.0
model_type: qwen3
tf_legacy_loss: False
use_bfloat16: False
